{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MukeshSiddh/Companion-Arbiter-PUF/blob/main/Mukesh_CS771_eval_assn1_23_24_II.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhdpwdE1z5aU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#from submit import my_map\n",
        "#from submit import my_fit\n",
        "import time as tm\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "import scipy\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7Xhjyzt3E5K"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "def my_map(X):\n",
        "    C = 2*X - 1\n",
        "    D = np.flip(C, axis=1)\n",
        "    X = np.cumprod(D, axis=1)\n",
        "    X = np.flip(X, axis=1)\n",
        "    ones_column = np.ones((X.shape[0], 1))\n",
        "    X = np.hstack((X, ones_column))\n",
        "\n",
        "    num_features = X.shape[1]\n",
        "    num_new_features = (num_features * (num_features - 1)) // 2\n",
        "\n",
        "    X_final = np.empty((X.shape[0], num_new_features))\n",
        "    index = 0\n",
        "    for i in range(num_features):\n",
        "        for j in range(i + 1, num_features):\n",
        "            X_final[:, index] = X[:, i] * X[:, j]\n",
        "            index += 1\n",
        "\n",
        "    print(X_final.shape)\n",
        "    return X_final\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Z_tst = np.loadtxt( \"secret_test.dat\" )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# def my_map2(X):\n",
        "#     C = 2*X - 1\n",
        "#     D = np.flip(C, axis=1)\n",
        "#     X = np.cumprod(D, axis=1)\n",
        "#     X = np.flip(X, axis=1)\n",
        "#     X_final = X\n",
        "\n",
        "#     for i in range(X.shape[1]):\n",
        "#         # Multiply the ith column with the matrix formed from i+1th column to the last column\n",
        "#         col_i = np.expand_dims(X[:, i], axis=1)\n",
        "#         submatrix = X[:, i+1:]\n",
        "#         new_features =col_i*submatrix\n",
        "#         X_final = np.hstack((X_final, new_features))\n",
        "\n",
        "#     print(X_final.shape)\n",
        "#     return X_final\n",
        "\n",
        "\n",
        "\n",
        "# import numpy as np\n",
        "\n",
        "# def my_map2(X):\n",
        "#     C = 2*X - 1\n",
        "#     D = np.flip(C, axis=1)\n",
        "#     X = np.cumprod(D, axis=1)\n",
        "#     X = np.flip(X, axis=1)\n",
        "#     ones_column = np.ones((X.shape[0], 1))\n",
        "#     X = np.hstack((X, ones_column))\n",
        "\n",
        "#     num_features = X.shape[1]\n",
        "#     num_new_features = (num_features * (num_features - 1)) // 2\n",
        "\n",
        "#     X_final = np.empty((X.shape[0], num_new_features))\n",
        "#     index = 0\n",
        "#     for i in range(num_features):\n",
        "#         for j in range(i + 1, num_features):\n",
        "#             X_final[:, index] = X[:, i] * X[:, j]\n",
        "#             index += 1\n",
        "\n",
        "#     print(X_final.shape)\n",
        "#     return X_final\n",
        "\n",
        "\n",
        "# t_map = 0\n",
        "# tic = tm.perf_counter()\n",
        "# feat = my_map2( Z_tst[:, :-1] )\n",
        "# toc = tm.perf_counter()\n",
        "# t_map += toc - tic\n",
        "# print(t_map)"
      ],
      "metadata": {
        "id": "oou9-AfZR4af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDiCwzkksbQ_"
      },
      "outputs": [],
      "source": [
        "# def my_fit(X_train, y_train):\n",
        "\n",
        "#     # Map the challenges to feature vectors\n",
        "#     X_train_mapped = my_map(X_train)\n",
        "\n",
        "#     # Initialize Logistic Regression model\n",
        "#     clf = LogisticRegression(max_iter=1000)\n",
        "\n",
        "#     # Fit the model\n",
        "#     clf.fit(X_train_mapped, y_train)\n",
        "\n",
        "#     # Extract coefficients (weights) and intercept (bias)\n",
        "#     w = clf.coef_.flatten()  # Coefficients of the linear model\n",
        "#     b = clf.intercept_[0]    # Intercept of the linear model\n",
        "\n",
        "#     return w, b\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# def my_fit(X_train, y_train):\n",
        "#     # Map the challenges to feature vectors\n",
        "#     X_train_mapped = my_map(X_train)\n",
        "#     # Scale the data\n",
        "#     scaler = StandardScaler()\n",
        "#     X_train_scaled = scaler.fit_transform(X_train_mapped)\n",
        "#     # Initialize Logistic Regression model\n",
        "#     clf = LogisticRegression(max_iter=10000)\n",
        "\n",
        "#     # Define hyperparameters to tune\n",
        "#     parameters = {\n",
        "#         'C': [10, 100,1000],  # Regularization parameter\n",
        "#         #'penalty': ['l1', 'l2']  # Regularization penalty\n",
        "#     }\n",
        "\n",
        "#     # Perform grid search with cross-validation\n",
        "#     grid_search = GridSearchCV(clf, parameters, cv=5, n_jobs=-1)\n",
        "#     grid_search.fit(X_train_mapped, y_train)\n",
        "\n",
        "#     # Get the best model\n",
        "#     best_clf = grid_search.best_estimator_\n",
        "#     print(\"Best Parameters of the Classifier:\")\n",
        "#     print(grid_search.best_params_)\n",
        "#     # Fit the best model\n",
        "#     best_clf.fit(X_train_mapped, y_train)\n",
        "\n",
        "#     # Extract coefficients (weights) and intercept (bias)\n",
        "#     w = best_clf.coef_.flatten()  # Coefficients of the linear model\n",
        "#     b = best_clf.intercept_[0]    # Intercept of the linear model\n",
        "\n",
        "#     return w, b\n",
        "\n",
        "def my_fit(X_train, y_train):\n",
        "    # Map the challenges to feature vectors\n",
        "    X_train_mapped = my_map(X_train)\n",
        "\n",
        "    # Scale the data\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_mapped)\n",
        "\n",
        "    # Initialize Logistic Regression model with C=100\n",
        "    clf = LogisticRegression(C=100, max_iter=10000)\n",
        "\n",
        "    # Fit the model\n",
        "    clf.fit(X_train_mapped, y_train)\n",
        "\n",
        "    # Extract coefficients (weights) and intercept (bias)\n",
        "    w = clf.coef_.flatten()  # Coefficients of the linear model\n",
        "    b = clf.intercept_[0]    # Intercept of the linear model\n",
        "\n",
        "    return w, b\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0salcYbPVeY"
      },
      "outputs": [],
      "source": [
        "Z_trn = np.loadtxt( \"secret_train.dat\" )\n",
        "Z_tst = np.loadtxt( \"secret_test.dat\" )\n",
        "\n",
        "n_trials = 5\n",
        "\n",
        "d_size = 0\n",
        "t_train = 0\n",
        "t_map = 0\n",
        "acc = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwn4Alu6Pz1u",
        "outputId": "4b4bc47c-7b25-444b-fae9-b10745a037e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40000, 528)\n",
            "(10000, 528)\n",
            "(40000, 528)\n",
            "(10000, 528)\n",
            "(40000, 528)\n",
            "(10000, 528)\n",
            "(40000, 528)\n",
            "(10000, 528)\n",
            "(40000, 528)\n",
            "(10000, 528)\n"
          ]
        }
      ],
      "source": [
        "for t in range( n_trials ):\n",
        "\ttic = tm.perf_counter()\n",
        "\tw, b = my_fit( Z_trn[:, :-1], Z_trn[:,-1] )\n",
        "\ttoc = tm.perf_counter()\n",
        "\tt_train += toc - tic\n",
        "\n",
        "\td_size += w.shape[0]\n",
        "\n",
        "\ttic = tm.perf_counter()\n",
        "\tfeat = my_map( Z_tst[:, :-1] )\n",
        "\ttoc = tm.perf_counter()\n",
        "\tt_map += toc - tic\n",
        "\n",
        "\tscores = feat.dot( w ) + b\n",
        "\tpred = np.zeros_like( scores )\n",
        "\tpred[scores > 0] = 1\n",
        "\tacc += np.average( Z_tst[ :, -1 ] == pred )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVG4OM_PQ1EG",
        "outputId": "063e8ecc-a5da-48c5-c688-50f24b223ce7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "528.0 2.1085357193999696 0.08965013539991559 0.9930999999999999\n"
          ]
        }
      ],
      "source": [
        "d_size /= n_trials\n",
        "t_train /= n_trials\n",
        "t_map /= n_trials\n",
        "acc /= n_trials\n",
        "\n",
        "print( d_size, t_train, t_map,  acc )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chFCWgFIysnU",
        "outputId": "53eb5d7a-12e2-47aa-8748-699af5c88ab5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 528)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "feat.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEUIc6xBy_jn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGFLN_j-nKfn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MT3f5ItzoMQE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
